# Change checklist (Kickoff meeting simulator)

Цель: проект имитирует реальное стартовое собрание (человек = CEO) и выдаёт **готовый финальный документ** (Markdown + JSON) без падений и с корректным наполнением.

## Token budget (чтобы не выйти за бесплатные лимиты)

Ограничения бесплатных токенов (по твоему сообщению):
- **“Сильный пул” 250k/день**: `gpt-5.2`, `gpt-5.1`, `gpt-5.1-codex`, `gpt-5`, `gpt-5-codex`, `gpt-5-chat-latest`, `gpt-4.1`, `gpt-4o`, `o1`, `o3`.
- **“Средний/mini пул” 2.5M/день**: `gpt-5.1-codex-mini`, `gpt-5-mini`, `gpt-5-nano`, `gpt-4.1-mini`, `gpt-4.1-nano`, `gpt-4o-mini`, `o1-mini`, `o3-mini`, `o4-mini`, `codex-mini-latest`.

Цель чеклиста ниже: **1 план проекта** желательно уложить в лимиты одного дня; либо гарантированно уложить **2 встречи в 2 разных дня** (по 1–3 фазы за встречу).

### Рекомендуемая конфигурация “по умолчанию” (самое простое и эффективное)
- [ ] В `.env` поставить `MODEL_PROVIDER=openai` и **не включать** платные бэкапы (либо оставить `BACKUP_MODEL_PROVIDERS` пустым), чтобы случайно не уйти в провайдеров без бесплатных токенов.
- [ ] В `.env` включить экономию контекста: `SMART_FORGETTING=true`.
- [ ] В `.env` уменьшить окно контекста: `CONTEXT_WINDOW_TURNS=4` (или `3`, если ответы большие).
- [ ] В `.env` поставить `PHASE_MEMORY_LIMIT=1` (или `0`, если нужно максимально экономно).
- [ ] В `.env` при необходимости снизить ходы: `MAX_TURNS_PER_PHASE=12` (оставить `16`, если качества мало, но тогда сильный пул расходуется быстрее).

### Рекомендуемый маппинг моделей (чтобы “сильный пул” не выжигался)
Файл: `project/config/model_config.yaml` (provider `openai` / `cloud`).
- [ ] Оставить **только фасилитатора** на “сильном пуле” (например, `gpt-5.2`/`gpt-5.1`) — это главный оркестратор и место, где качество заметнее всего.
- [ ] Перевести остальных участников на “mini пул” (например: `gpt-4.1-mini` / `o4-mini` / `gpt-5-mini` / `gpt-4.1-nano`).
- [ ] Если архитектура/безопасность получаются слабо — временно поднять **только одну** роль (например, `architect` или `security_specialist`) в “сильный пул” и вернуться обратно после нужной фазы.

### Стратегия “2 встречи в 2 разных дня” (если хочешь железно не упираться в лимиты)
- [ ] День 1: Requirements Gathering + System Design.
- [ ] День 2: Implementation Planning + Testing Strategy + Deployment Planning + Maintenance Strategy.

---

## 0) Acceptance criteria (что считаем «готово»)
- [ ] Запуск `python project/main.py` и `python project/main_ui.py` проходит без исключений.
- [ ] В конце всегда появляется Markdown-план и JSON-снимок; Markdown содержит реальные данные из обсуждения (не плейсхолдеры) как минимум по фазе Requirements.
- [ ] На неидеальных ответах LLM (нестрогое JSON, странные типы, пустые поля) сессия не падает.
- [ ] Роль человека в UI/логах/инструкциях явно «CEO».

---

## 1) Немедленно исправить (ломает запуск или «готовый финальный документ»)

### 1.1 Исправить импорт `DocumentMonitorAgent`
- [ ] Файл: `project/orchestration/waterfall_controller.py`
- [ ] Проблема: импорт идёт как `from project.agents.document_monitor import DocumentMonitorAgent`, тогда как остальные импорты — `from agents...`.
- [ ] Риск: `ModuleNotFoundError` при обычном запуске из папки `project/`.
- [ ] Ожидаемый результат: единый стиль импортов и запуск без ошибок.

### 1.2 Сделать безопасный парсинг `readiness_score`
- [ ] Файл: `project/orchestration/waterfall_controller.py`
- [ ] Места: присваивание `readiness_score = int(...)` в `_run_single_phase` и `_print_facilitator_turn`.
- [ ] Проблема: LLM может вернуть `"75"`, `"75/100"`, `null`, `"high"` → `ValueError`.
- [ ] Ожидаемый результат: устойчивый парсер/нормализатор (fallback на 0/оценку по `artifact_check`).

### 1.3 Привести финальный Markdown-шаблон в соответствие со схемой артефактов
- [ ] Файл: `project/output/templates.py`
- [ ] Проблема: шаблон читает `clarifications/requirements/constraints`, а сборка артефакта требований даёт `functional_requirements/non_functional_requirements/stakeholders/success_criteria/open_questions/...`.
- [ ] Риск: итоговый документ выглядит «пустым» и не соответствует ТЗ «готовый финальный документ».
- [ ] Ожидаемый результат: Markdown использует реальные поля артефакта (например, `stakeholders`, `success_criteria`, `functional_requirements`, `non_functional_requirements`, `constraints`, `open_questions`, `coverage_good/gaps`).

### 1.4 Пересмотреть учёт лимитов ходов (фаза “съедается” фасилитатором)
- [ ] Файлы: `project/orchestration/meeting_state.py`, `project/orchestration/waterfall_controller.py`
- [ ] Проблема: `add_transcript()` увеличивает `turn_count` для **любого** спикера, включая `facilitator`.
- [ ] Риск: при `MAX_TURNS_PER_PHASE=16` фактически остаётся ~8 «полезных» ходов специалистов; повышается шанс недостижения сходимости.
- [ ] Варианты решения (выбрать один):
  - [ ] Не считать `facilitator` в `turn_count` (но считать в `total_turns`).
  - [ ] Разделить счётчики: `phase_turns` (специалисты) и `meta_turns` (фасилитатор/система).

---

## 2) Лучше изменить (качество логики/реализм «CEO + собрание»)

### 2.1 Явно закрепить человека как «CEO»
- [ ] Файлы: `project/agents/human_stakeholder.py`, `project/interaction/channel.py`, (опционально) промпт фасилитатора в `project/prompts/role_prompts.py`.
- [ ] Проблема: сейчас роль человека в коде/логах = `human_stakeholder`, но в ТЗ человек выступает как CEO.
- [ ] Ожидаемый результат: в выводе/логах/инструкциях фигурирует «CEO», чтобы LLM корректно адресовал вопросы и решения.

### 2.2 Согласовать промпты ролей с ожидаемой схемой артефактов
- [ ] Файлы: `project/prompts/role_prompts.py`, `project/orchestration/phase_artifacts.py`
- [ ] Пример несостыковки: `phase_artifacts.py` ждёт у BA `non_functional_requirements`, но BA промпт это не просит.
- [ ] Ожидаемый результат: каждый критичный ключ артефакта явно запрашивается в промпте соответствующей роли.

### 2.3 Защититься от неизвестных фаз (чекпоинты/рефактор фаз)
- [ ] Файл: `project/prompts/phase_prompts.py`
- [ ] Проблема: прямой доступ к словарю по `phase_name` → `KeyError`, если фазы изменились или чекпоинт старый.
- [ ] Ожидаемый результат: явная валидация фазы с понятным сообщением и fallback.

---

## 3) Улучшить (устойчивость, качество результата, сопровождение)

### 3.1 Минимальная валидация JSON-ответов агентов
- [ ] Файлы: `project/orchestration/waterfall_controller.py`, (опционально) `project/orchestration/meeting_state.py`
- [ ] Цель: не принимать в `raw_contributions` payload без `role`/с неверной `phase`/не dict.
- [ ] Ожидаемый результат: меньше мусора → стабильнее `build_phase_artifact()`.

### 3.2 Один «источник истины» для структуры финального документа
- [ ] Файлы: `project/orchestration/phase_artifacts.py`, `project/output/templates.py`
- [ ] Цель: уменьшить рассинхрон между тем, что собираем, и тем, что печатаем.
- [ ] Подход: либо шаблон полностью строится по `schema_fields`, либо артефакт жёстко маппится в нужные секции документа.

### 3.3 Небольшие тесты (минимальный пакет)
- [ ] Добавить тесты на:
  - [ ] `build_phase_artifact()` для `Requirements Gathering` (ключи не пустые при валидных входах).
  - [ ] `render_markdown_plan()` — что выводит нужные секции/поля.
  - [ ] Нормализацию `readiness_score` на разных входах.

---

## 4) Примечания по edge cases (проверить вручную)
- [ ] CEO даёт пустое описание проекта → документ не должен ломаться; должны появляться уточняющие вопросы.
- [ ] LLM возвращает невалидный JSON → система должна продолжать (fallback/переспрос/пустой вклад).
- [ ] Чекпоинт повреждён/не читается → продолжить с новой сессией без падения.
- [ ] `MEETING_LANGUAGE=ru` → все текстовые значения в JSON реально на русском.
